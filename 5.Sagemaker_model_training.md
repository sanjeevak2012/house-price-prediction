# Training a model on sagemaker
1) Create an `iam user` or use `root user` (Just for POC) for mlflow with `s3 full access permission` and create its access keys
aws -> iam
2) Create an `s3 bucket` and enable public access
aws -> s3
3) create an `ec2 server` and run below commands
aws -> ec2
```bash
#!/bin/bash
sudo apt update -y
sudo apt install python3.12-venv  python3-pip unzip -y
echo "done" > /home/ubuntu/result

mkdir /home/ubuntu/mlflow
cd /home/ubuntu/mlflow
python3 -m venv myproject_venv && source myproject_venv/bin/activate

pip3 install mlflow awscli boto3 setuptools
```
4) use `aws configure` command and configure it with your `mlflow user` creds
5) start the mlfow server using below just `change the s3 bucket name` at the end
```bash
mlflow server -h 0.0.0.0 --backend-store-uri sqlite:///mlflow.db --default-artifact-root s3://mlflow-artifact-storage-poc
```
6) `allow port 5000` in your `security group` of `mlflow ec2 server`
7) open `yourinstanceip:5000` in your favourite browser

8) https://github.com/Kapil987/house-price-prediction# either you can fork it or clone the repo code in your local and then push it to your repository
```bash
git clone https://github.com/Kapil987/house-price-prediction# 
```
9) Go to `Amazon SageMaker AI` service in amazon and click on `Notebook Instances` Option,
- click on `Git repositories` then `Add repository`
- under repository settings choose `GitHub/Other Git-based repo` and provide your repo details and add it
  - provide `Amazon SageMaker repository name` and `Git Repository URL`
  - for public repos choose Git credentials as `No Secret`
  - then click on add repository
- create a `sagemaker role` for the instance having 
  - `AmazonS3FullAccess`
  - `EC2InstanceProfileForImageBuilderECRContainerBuilds`
  - `AmazonSageMakerFullAccess`
10) Go to `Amazon SageMaker AI` service in amazon and click on `Notebook Instances` Option, then click on `Create notebook instance`
- provide `Notebook instance name`
- Notebook instance type should be `ml.t3.large`
- choose your `sagemaker iam role`
- under `Git repositories - optional`
  - add your repository under `Default repository` from drop down
- leave rest settings default
- click on `Create notebook instance`

11) wait for the `status` to be `InService` then click on notbook instance name and then `Open Jupyter lab`

12) Look for `Launcher` named tab scroll down and click on `Terminal`
13) in the `terminal` run below commands, we are installing mlflow only to run the run.py file, the actual training environment will be created automatically by MLflow using the conda file.
```bash
pip install mlflow
```
14) change the `tracking uri` in `run.py` to your mlflow ec2 instance `python run.py`
15) the first run might have run the elasticnet model, now change the model to ridge and xgbregressor and re-run `python run.py` 
16) Go to each experiment and based on a metric select best run, example the one with low r2 score, and register the model
17) Repeat step 16 for each model
18) select all the model you registered from previous steps and compare, and you may choose the one with high r2 score
19) You may put alias as dev, stage, prod as required, this step is option for this poc
20) To deploy the model go to your sagemaker notebook terminal and use below
the container name could be anything, but it should be in small case
```bash
mlflow sagemaker build-and-push-container --container xgb --env-manager conda
```
The mlflow sagemaker `build-and-push-container` command itself does not deploy a specific model. Its primary purpose is to:

- Build a Docker image that contains the necessary MLflow dependencies and inference server to serve any MLflow pyfunc model.
- Push that Docker image to Amazon Elastic Container Registry (ECR).

21) Go to you `deploy.py` file and provide 
- prod endpoint name 
- model uri from mlflow of your best model
- execution_role_arn which is the role of you sagemaker notebook instance
- bucket_name where your mlflow artifacts are stored
- image_url : the ecr repo url
- region_name : the region name
- instance_type
- instance_count

22) execute `python deploy.py` this will create an endpoint, you can view this , Go to `Amazon SageMaker AI` service in amazon and click on `Inferance` > endpoints
23) change endpoint_name in `test.py` and then run `test.py`
24) To generate conda.yaml use command 
```bash
conda env export > conda.yaml
```
25) to create a conda environment form `.yaml` file use below command
```bash
conda env create -f conda.yaml
```
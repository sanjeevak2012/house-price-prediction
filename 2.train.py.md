# 2.train.py
---

# ML Model Training with MLflow

This project helps us train machine learning models and keep track of all our experiments using **MLflow**, a cool tool that's like a scientific notebook for machine learning.

Imagine you're a chef trying to perfect a new recipe. You'll try different ingredients (models) and different amounts of spices (hyperparameters). MLflow is like your recipe book where you note down:
* Which ingredients you used.
* How much of each spice you added.
* How good the dish tasted (performance metrics).
* The final cooked dish itself (trained model).
* Even the exact cooking steps you followed!

This makes it super easy to compare different versions of your recipe and find the best one.

## How it Works (Simple Explanation)

We're going to train a bunch of different machine learning models, specifically for problems where we need to predict a number (like predicting house prices or sales, which is called "regression").

We won't just pick one model and guess its settings. Instead, we'll try:
1.  **Multiple "recipes" (Machine Learning Models):** Like `ElasticNet`, `Ridge`, and `XGBoost`.
2.  **Different "spice levels" (Hyperparameters):** These are the settings for each model that make it perform better or worse.
3.  **Automatically trying combinations:** Instead of manually mixing spices, we use a smart tool called `ParameterGrid` to try all the interesting combinations for us.
4.  **Logging Everything with MLflow:** Every time we try a new recipe (a model with specific spice levels), MLflow records everything: what we used, how it performed, and even saves the finished model. This way, we can always go back and see what worked best.

## What is XGboost
**XGBoost (eXtreme Gradient Boosting)** is a very popular and powerful **machine learning model**.

More specifically, it's an implementation of **gradient boosting machines (GBMs)**, which is an ensemble learning method. This means it builds a strong predictive model by combining the predictions of many weaker models, typically decision trees.

## Code Breakdown (Line by Line)

Let's break down the `train.py` script:

```python
import mlflow
import numpy as np
from data import X_train, X_val, y_train, y_val
from sklearn.linear_model import Ridge, ElasticNet
from xgboost import XGBRegressor
from sklearn.model_selection import ParameterGrid
from params import ridge_param_grid, elasticnet_param_grid, xgb_param_grid
from utils import eval_metrics
```
* `import mlflow`: This brings in the MLflow library, our "smart notebook" for tracking experiments.
* `import numpy as np`: A common library for working with numbers, especially in scientific computing.
* `from data import X_train, X_val, y_train, y_val`: We're importing our training and validation data (features `X` and labels `y`) from a separate file named `data.py`. Think of `X` as the ingredients list and `y` as the expected taste for our recipe.
* `from sklearn.linear_model import Ridge, ElasticNet`: Importing two specific types of "linear regression" models from the `scikit-learn` library. These are like two different types of ovens.
* `from xgboost import XGBRegressor`: Importing another powerful model called `XGBoost`, which is great for regression. This is like a high-tech smart oven.
* `from sklearn.model_selection import ParameterGrid`: This is our "automatic spice mixer." It helps us easily create all possible combinations of hyperparameters we want to try for our models.
* `from params import ridge_param_grid, elasticnet_param_grid, xgb_param_grid`: We're importing dictionaries from `params.py` that define which "spice levels" (hyperparameters) we want to try for each of our `Ridge`, `ElasticNet`, and `XGBoost` models.
* `from utils import eval_metrics`: We import a special function from `utils.py` that helps us measure how good our cooked dish (model) tastes. It calculates metrics like errors and accuracy.

```python
# Loop through the hyperparameter combinations and log results in separate runs
for params in ParameterGrid(elasticnet_param_grid):
    with mlflow.start_run():
```
* `for params in ParameterGrid(elasticnet_param_grid):`: We start a loop. For every unique combination of "spice levels" (hyperparameters) defined for `ElasticNet` in `elasticnet_param_grid`, this loop will run once.
* `with mlflow.start_run():`: **This is crucial for MLflow!** Each time this line runs, MLflow creates a new, separate "experiment record" (called a "run"). It's like opening a new page in your notebook for each distinct attempt at your recipe. All the logging we do inside this `with` block will be associated with this specific run.

```python
        lr = ElasticNet(**params)
        lr.fit(X_train, y_train)
        y_pred = lr.predict(X_val)
        metrics = eval_metrics(y_val, y_pred)
```
* `lr = ElasticNet(**params)`: We create a new `ElasticNet` model. The `**params` part means we're applying the current "spice level" combination from our `ParameterGrid` to this model.
* `lr.fit(X_train, y_train)`: We "train" our model using the training data (`X_train` are the features, `y_train` are the correct answers). This is like our chef actually cooking the dish.
* `y_pred = lr.predict(X_val)`: After training, we ask our model to "predict" the answers for our `X_val` (validation features), which it hasn't seen before. This is like tasting our dish after cooking.
* `metrics = eval_metrics(y_val, y_pred)`: We use our `eval_metrics` function to compare the model's predictions (`y_pred`) with the actual correct answers (`y_val`) for the validation data. This gives us a score on how well our model performed, like a taste test score.

```python
        # Logging the inputs such as dataset
        mlflow.log_input(
            mlflow.data.from_numpy(X_train.toarray()),
            context='Training dataset'
        )

        mlflow.log_input(
            mlflow.data.from_numpy(X_val.toarray()),
            context='Validation dataset'
        )
```
* `mlflow.log_input(...)`: These lines record the actual training and validation datasets into our MLflow run. It's like writing down in your recipe book, "I used these specific carrots and potatoes." This ensures we know exactly what data was used for this particular experiment.

```python
        # Logging hyperparameters
        mlflow.log_params(params)

        # Logging metrics
        mlflow.log_metrics(metrics)
```
* `mlflow.log_params(params)`: We tell MLflow to record all the "spice levels" (hyperparameters) that were used for this specific model training run. This is like noting down "1 teaspoon salt, 2 tablespoons sugar."
* `mlflow.log_metrics(metrics)`: We tell MLflow to record the "taste test scores" (evaluation metrics) we calculated. This is like writing "Dish tasted 8/10, slightly salty."

```python
        # Log the trained model
        mlflow.sklearn.log_model(
            lr,
            "ElasticNet",
             input_example=X_train,
             code_paths=['train.py','data.py','params.py','utils.py']
        )
```
* `mlflow.sklearn.log_model(...)`: This is super important! We save our entire trained model (`lr`) into MLflow. It's like putting the "finished dish" into a special container and labeling it.
    * `"ElasticNet"`: This is just a name for our saved model.
    * `input_example=X_train`: We provide a small example of the input data the model expects. This helps MLflow understand how to use the model later.
    * `code_paths=['train.py','data.py','params.py','utils.py']`: This tells MLflow to also save copies of the code files that were used to train this model. This is like attaching the exact recipe card (`train.py`), ingredient list (`data.py`), spice settings (`params.py`), and tasting method (`utils.py`) to your stored dish. This ensures you can always reproduce your results!

---

This `train.py` script is designed to be very flexible. Things like experiment names or where MLflow saves its data aren't set here directly. That's because those details are usually decided when you actually *run* this code as part of a larger MLflow project, which is set up in a file called `MLproject`. This makes our `train.py` reusable across different projects and environments!